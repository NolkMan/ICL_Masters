\documentclass[11]{article}   % list options between brackets

\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{float}
\usepackage[citestyle=alphabetic,bibstyle=authortitle]{biblatex}
\usepackage[a4paper,  margin=1in]{geometry}

\addbibresource{citations.bib}

\begin{document}

\title{COMP70004 Advanced Computer Security\\Coursework 2 Report} 
\author{Michal Glinski (mjg222)}    

\maketitle

\section{Content Security Policy}
\subsection{Overview}
Content Security Policy(CSP) was introduced as a protection layer, which allows webhosts to control origin and type of resources loaded in the client browser. 
W3 organization recommends using CSP as a defence-in-depth tool, which can help reduce the harm caused by malicious users, but it should not be the sole security measure taken to prevent attacks. \cite{CSPLevel3}
CSP works by providing the user browser a list of directives, where each resource type, like scripts, stylesheets and images, have its own set of rules.
Those can include allowed URL endpoints, hashes of expected objects or nonces which may allow for otherwise unsafe inline scripts.

The most common usage of CSP in literature it to limit the resources loaded to prevent attacks such as XSS.
This method can also help with other exfiltration attacks based on CSS.
CSP has many ways to protect browser users from malitious content.

To protect users from packet sniffing, developers can use \texttt{upgrade-insecure-requests}.
Using this directive will instruct the browser to try and send all requests by https, otherwise the resource will fail to load.
Using CSP with \texttt{default-src https:} will instead immidiately drop all insecure requests.

CSPs can also protect from clickjacking and phishing attacks with specialized frame controls. 
\texttt{frame-src}, \texttt{frame-ancestors}, \texttt{sandbox} all control what behaviours the appliction may allow.
\begin{enumerate}
	\item \texttt{frame-src} controls which urls can be included as frames in the website
	\item \texttt{frame-ancestors} controls what websites can include this page in a frame. 
	\item \texttt{sandbox} controls what the loaded website can perform as if it was loaded into an sandbox iframe. With this it is possible to forbid downloads or scripts alltogether.
\end{enumerate}
Paper by Roth Et Al. analizes tendencies in CSP deployment between 2012 and 2018 and shows increased interest in deploying CSP to limit framing options of websites. \cite{osti_10173479}
It is theoretised this may be due to the limited control that \texttt{X-Frame-Options} provide, as CSP allows to specify frame origins and is better supported by browsers.
Developing a CSP with framing options is also relatively easier, as there are fewer directives and the attack surface is smaller.


CSP is constantly being developed with currently 3rd version being in draft, while major parts of it are already being implemented into modern browsers.
With CSP3 \texttt{scirpt-src} directive has been further split into \texttt{script-src-elem} and \texttt{script-src-attr} directives which seperate rule for javascript coming from \texttt{<script>} markup tags and attributes such as \texttt{onClick} event attribute.
Additionally it allows to specify hashes of sources allowed to load and enhancements to \texttt{sandbox} directive, which allows for more control over potentially untrusted content running in its isolated environment.

The newest experimental feature of CSP3 are \texttt{require-trusted-types-for} and \texttt{trusted-types} directives. \cite{TTwebdev} \cite{TTmozdev}
To further prevent DOM based XSS attacks, they allow developers to control data data that comes into unsafe sinks.
By using specially designed parsers and filters all elements can be checked before they are dynamically added to the website.
%% talk about already designed filters
In this way trusted types reduce the attack surface even further and require the attacker to work much harder when creating an exploit.

CSP3 is designed to be backwards compatible with CSP2, which is to ensure that new features do not prevent webpages from displaying correctly on older clients.
For example when nonces or hashes are included, the \texttt{unsafe-inline} rule is ignored by the browsers.
This allows for new features to be deployed sooner, but it may sacrifice the security of older clients.

% talk about css exfil attacks

\subsection{Implementing CSP}
Implementing CSP, although potential security benefits, comes with its own fair share of problems. 
They span multiple layers and are especially noticable when trying to add CSP to a big, long lasting project.

One of the hardest problems to overcome is when the web application uses inline scripts or event attributes that allow for scripting, like \texttt{onClick} event handler.
While it is possible to still use inline scripts with hashes or nonces, CSP disincetivies the usage of inline javascript as it is a common entry point for XSS attacks. 

Strong cryptographic security of hashes ensures that only allowed scripts will execute. 
Attacker in this situation can execute the same script multiple times and abuse the sideeffects it may have.
When using \texttt{unsafe-hashes}, hashes can also be used for event handlers, which still may prove to be better than nothing.
The biggest downside of CSP hashes is when using them to secure 3rd party sources, as the CSP needs to be updated with every sourcecode change.

The other option requires that every script is accompanied with a random nonce value.
In theory when nonce is regenerated with every response, the attacker will be unable to execute scripts as they will be unable to predict the value.
Unfortunatelly, nonces have been shown to be potentially unsecure and fall to more advanced attacks. \cite{noncesGoBrrr}
Those attacks oftentimes rely on confusing the browser, which despite invalid html syntax still tries to display the page.

All the issues and methods can also be applied to stylesheets, as those may also be DOM injected in similar manner to javascript. \cite{cssinjection} \cite{cssexfil}
With more modern attacks that may use pure stylesheets to exfiltrate data about users, it is important to secure CSS cources too.
While those attacks are usually more complex in execution and the payload size, they can still be mitigated by a well designed CSP.

Another big problem when developing a CSP is enumerating legitimate dependencies of the website.
Addition of new dependencies may go unnoticed in a quick developing environments of many webapps.
Users may also inject their own code in form of plugins into web applicaitons, which will generate false reports.
This behaviour is well highlighted by a blogpost by dropbox when they were developing a CSP for their own applications. \cite{dropboxcsp}
The dropbox team had to create a list of strings, some of which included endpoints of other apis, to filter those reports.

While deploying a csp developers may also use tools already available on the web. 
csp-evaluator.withgoogle.com allows for checking the CSP or the website itself against a big set of vulnerabilities, described in a paper by Weichselbaum Et Al. \cite{weichselbaum2016csp}
Those were collected in a comprehensive research aggregating CSP usage and vulnerabilities which can result in the attacker bypassing the policies.

Hosts may also use one of many commercialy available CSP generation tools.
csper.io helps in deploying and maintaining a CSP header by automatically gathering, filtering and sorting reports. 
Tools like that can increase the overall security of the website, but automation may not be perfect too. 
It may help create a CSP with holes created by plugins loaded by users.
This can later lead to a CSP bypasses where the malicious user leverages small misconfigurations to gain access.
Additionally when an attack is already ongoing it may be difficult to differentiate its reports from genuine traffic.

When deplying CSP it is important to remember that maintaining it requires constant effort from the developers.
Unupdated CSP can make the webpage misbehave or be completely unusable when required sources are blocked from loading.
This is a risk that may negatively impact user experience, which in turn can lead to loss of revanue.

% angular js problemsk

\subsection{Bypassing CSP}
Even though CSP can prevent many basic attacks it may be unsuccessful at blocking more advanced exploits.
A study by Weichselbaum Et Al. done in 2016 showcases many ways in which CSP may be ineffective. \cite{weichselbaum2016csp}
It shows how libraries can be used to bypass CSP policies.
Angular, for example, allows malicious users to bypass CSP with DOM injection as it allows expression evalueation with a markup attribute.
This behaviour may also be exploited on websites not using such libraries, as long as any CSP whitelisted endpoint exposes those sources.

Another vulnerable library they highlight is jsonp which allows for callbacks.
Those can be used to trick the enpoint in passing malicious code back to the user, disregarding CSP.

They conclude that nearly all CSPs they have found are trivially bypassable and do not provide any additional security.

CSP nonces also came under scrutiny, where they can also be bypassed in multiple ways.
Here exploits are more refined and often rely on browsers trying to display incorrect html.
Blog by XSS Jigsaw demonstrates how twitter was found to have a XSS vulnerability where nonce could be stolen from a different script tag. \cite{noncesGoBrrr}
This blog also provides another example where a user token could be stolen with a link markup tag and a clever redirect.

On his webpage, Sebastian Lekies, collected a bunch of CSP nonce bypasses in the form of internet directory with links to examples and original finders. \cite{noncesGoExtinct}
The list contains methods which use partial markup injections (like in the twitter example), CSS and even DOM based XSS among the others.
It also contains examples of how many major libraries (jQuerry, Angular, Ember, JSONP) can be used to bypass CSP, sometimes even providing multiple ways to achieve a bypass.

Content exfiltration is also another problem which we may like to solve with a content security policy.
Attackers after compromising the website may be interested in exporting user data, like passwords or credit card information, to their own servers.
Fortunatelly browsers block resources violating the CSP before sending any requests.
This behaviour combined with a very strict CSP would disallow for any data to be exfiltrated in case of an XSS attack.

Unfortunatelly, paper by Acker Et Al. presents a comprahensive analisys of 
 

% <!doctype html>
% <html>
% 	<head>
% 		<meta charset="utf=-8">
% 		<title> SCP Workspace </title>
% 		<script src="https://attacker.fun:4433/alert.js" integrity="sha256-acrDren6qaZiQCY/9ynh5uP2E1lj3CIyO0G0g+nD9qk=" crossorigin="anonymous"></script>
% 		<script src="https://attacker.fun:4433/alert2.js"></script>
% 	</head>
% 	<body>
% 		<h1> SCP Workspace </h1>
% 		<p> xd </p>
% 		<img src=https://attacker.fun/rose.jpg>
% 	</body>
% </html>


% CSP allows to bolster the security of inline scripts by adding hash and nonce based source values.
% Nonce is supposed to be a unique, random value, which would mean that the malicious script will be blocked.
% Both solutions have their problems, hashes may allow a specific script to be loaded multiple times, which is especially problematic if the script has side effects.
% Nonces on the other hand have been shown to be bypassable with carefully crafted payloads \cite{???}.



\subsection{Report-Only Header}
Content Security Policy offers many benefits to protect users from attacks by selectively allowing safe recources to be loaded.
But as established it takes a lot of team effort to implement and maintain, where small errors can lead to loss of security or user experience.
Thankfully CSP provides one more tool in form of the report only header.
It simulates the browser enforcing the CSP and allows for all the to be violations to be reported to the specified endpoints.

This tool is of major help when starting to create a new policy for a website.
It allows for testing and fune tuning of the policy before enabling it. 
The reports provide great insight into the structure of the application.
Additionally disabling all resources from loading is a quick and dirty way of obtaing a list of all resources that are loaded by clients.
The dropbox team used the report only feature extensively when deploying their own CSP, where they enumerated sources and tested their own CSP. \cite{dropboxcsp}

% Mozilla Developer Network - Content Security Policy
% https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP

Report only violations can give a valuable insight into attacks that are currently ongoing 
With careful monitoring attacks may be detected quicker, allowing developers to patch the issue and limit the impact of the adversary.
Additionally reports provide many insights into the violation, the type of the resource, the URL and even the line in which a rule was broken.
With the \texttt{report-sample} source, the report may include the first 40 characters of inlined script or stylesheet.

In literature CSP reporting seems to be an underutilized tool, as less than one in five websites that deploy CSP ever deployed CSPRO header. \cite{osti_10173479}
This may correspond to the poor effectiveness of deployed CSPs as developers may have never tried more strict policies in report only mode.
Even less websites use the RO header alongside CSP header, which may be one of the very few ways to progresively try and remove old dependencies from the already deployed CSP.

The CSP report-only header can be added to wny website without any consequences to the user experience and without modifying large pieces of code.
This may lead to overall increase to the security by solving security issues quicker.
It can also be deployed alongside an existing CSP to more strictly monitor sources which are known to be temporary or problematic.
Those may include external APIs or libraries, which may update and add new features which compromise security.

\printbibliography

\input{evalueation}

\end{document}
